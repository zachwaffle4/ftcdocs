<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />
 <meta name="google-site-verification" content="75RBwHq1pWFvK2E7wuVgAeq_LOOJrU4q1wRIjXqPpqg" />  <!-- Google Analytics Intentionally Disabled -->  <!-- Cookie Banner Intentionally Disabled --> 
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>TensorFlow for CENTERSTAGE presented by RTX &mdash; FIRST Tech Challenge Docs 0.3 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/tooltipster.custom.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/tooltipster.bundle.min.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/tooltipster-sideTip-shadow.min.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/tooltipster-sideTip-punk.min.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/tooltipster-sideTip-noir.min.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/tooltipster-sideTip-light.min.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/tooltipster-sideTip-borderless.min.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/micromodal.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/ftc-rtd.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/sphinx_rtd_theme.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/dark_mode_css/general.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/dark_mode_css/dark.css" />

  
    <link rel="shortcut icon" href="../../../_static/FIRSTicon_RGB_withTM.ico"/>
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/js/hoverxref.js"></script>
        <script src="../../../_static/js/tooltipster.bundle.min.js"></script>
        <script src="../../../_static/js/micromodal.min.js"></script>
        <script src="../../../_static/js/external-links-new-tab.js"></script>
        <script src="../../../_static/js/adjust-css-vars.js"></script>
        <script src="../../../_static/design-tabs.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script src="../../../_static/dark_mode_js/default_light.js"></script>
        <script src="../../../_static/dark_mode_js/theme_switcher.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="TensorFlow for POWERPLAY presented by Raytheon Technologies" href="../tensorflow_pp_2022/tensorflow_pp_2022.html" />
    <link rel="prev" title="AprilTag Challenges in DECODE presented by RTX" href="../../../apriltag/apriltag_tips/decode_apriltag/decode-apriltag.html" /> 
</head>

<body class="wy-body-for-nav"> 


<div class="header-bar">
        <!-- Color Strip -->
        <div class="color-strip">
            <div class="fred"></div>
            <div class="forange"></div>
            <div class="fblue"></div>
        </div>
        <div class="link-bar-container">
            <div id="link-bar" class="collapse">
                <ul>          
			<li id="ftc-page-link"><a href="https://www.firstinspires.org/resource-library/ftc/game-and-season-info" target="_blank"><i>FIRST</i> Official Team Resources</a></li>
                  <li id="qa-link"><a href="https://ftc-qa.firstinspires.org/" target="_blank">Official Game Q&A</a></li>
                </ul>
            </div>
        </div>
</div>

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            FIRST Tech Challenge Docs
              <img src="../../../_static/FIRSTTech_iconHorz_RGB_reverse.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                0.3.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../overview/ftcoverview.html">About the <em>FIRST</em> Tech Challenge</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../gracious_professionalism/gp.html"><em>Gracious Professionalism®</em></a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../persona_pages/rookie_teams/rookie_teams.html">New Teams</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../persona_pages/veteran_teams/veteran_teams.html">Returning Teams</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../persona_pages/coach_admin/coach_admin.html">Coach (Administrative) Resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../persona_pages/mentor_tech/mentor_tech.html">Technical Mentor Resources</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Game and Season-Specific Resources</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../game_specific_resources/blog/blog.html"><em>FIRST</em> Tech Challenge Blog</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tech_tips/tech-tips.html"><em>FIRST</em> Tech Challenge Tech Tips</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ai/innovation_corner/innovation-corner.html">AI Innovation Corner</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../manuals/game_manuals/game_manuals.html">Competition Manual</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../game_specific_resources/ftcqa/ftcqa.html">Game Q&amp;A System</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../game_specific_resources/playing_field_resources/playing_field_resources.html">Playing Field Resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../game_specific_resources/field_coordinate_system/field-coordinate-system.html">Field Coordinate System</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Software Development Kit (SDK)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../laptops/laptops.html">Laptop Requirements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ftc_sdk/overview/index.html">SDK Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ftc_sdk/updating/index.html">Updating Components</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Control System Resources</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../shared/control_system_intro/The-FTC-Control-System.html">Control System Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../control_hard_compon/index.html">Hardware Component Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../hardware_and_software_configuration/index.html">Hardware and Software Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../hardware_and_software_configuration/self_inspect/new-self-inspect.html"><em>FIRST</em> Tech Challenge Self-Inspect</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../hardware_and_software_configuration/self_inspect/self-inspect.html">Old Self-Inspect</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../index.html">Programming Resources</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../index.html#programming-tutorials">Programming Tutorials</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../index.html#supporting-documentation">Supporting Documentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../index.html#apriltag-programming">AprilTag Programming</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../../index.html#tensorflow-programming">TensorFlow Programming</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">TensorFlow for CENTERSTAGE presented by RTX</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#what-is-tensorflow">What is TensorFlow?</a></li>
<li class="toctree-l4"><a class="reference internal" href="#how-might-a-team-use-tensorflow-this-season">How Might a Team Use TensorFlow this season?</a></li>
<li class="toctree-l4"><a class="reference internal" href="#sample-opmodes">Sample OpModes</a></li>
<li class="toctree-l4"><a class="reference internal" href="#notes-on-training-the-centerstage-model">Notes on Training the CENTERSTAGE Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="#using-the-default-centerstage-model">Using the Default CENTERSTAGE Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="#selecting-objects-for-the-team-prop">Selecting objects for the Team Prop</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../tensorflow_pp_2022/tensorflow_pp_2022.html">TensorFlow for POWERPLAY presented by Raytheon Technologies</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tensorflow_ff_2021/tensorflow-ff-2021.html">TensorFlow for FREIGHT FRENZY presented by Raytheon Technologies</a></li>
<li class="toctree-l3"><a class="reference internal" href="../blocks_tfod_opmode/blocks-tfod-opmode.html">Blocks Sample OpMode for TFOD</a></li>
<li class="toctree-l3"><a class="reference internal" href="../blocks_tfod_opmode_custom/blocks-tfod-opmode-custom.html">Blocks Custom Model Sample OpMode for TFOD</a></li>
<li class="toctree-l3"><a class="reference internal" href="../java_tfod_opmode/java-tfod-opmode.html">Java Easy Sample OpMode for TFOD</a></li>
<li class="toctree-l3"><a class="reference internal" href="../java_tfod_opmode_custom/java-tfod-opmode-custom.html">Java Custom Model Sample OpMode for TFOD</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../index.html#vision-programming">Vision Programming</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../index.html#camera-color-processing">Camera Color Processing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../index.html#advanced-topics">Advanced Topics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../index.html#java-tutorials">Java Tutorials</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../index.html#additional-first-website-resources">Additional <em>FIRST</em> Website Resources</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Programming Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../shared/choosing_program_lang/choosing-program-lang.html">Choosing a Programming Tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blocks/Blocks-Tutorial.html">Blocks Programming Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../onbot_java/OnBot-Java-Tutorial.html">OnBot Java Programming Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../android_studio_java/Android-Studio-Tutorial.html">Android Studio Programming Tutorial</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">AprilTag Resources</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../apriltag/vision_portal/apriltag_intro/apriltag-intro.html">AprilTag Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../apriltag/vision_portal/visionportal_overview/visionportal-overview.html">VisionPortal Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../apriltag/vision_portal/visionportal_webcams/visionportal-webcams.html">Webcams for VisionPortal</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../apriltag/understanding_apriltag_detection_values/understanding-apriltag-detection-values.html">Understanding AprilTag Values</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../apriltag/vision_portal/apriltag_localization/apriltag-localization.html">AprilTag Localization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../apriltag/opmode_test_images/opmode-test-images.html">AprilTag Test Images</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">CAD Resources</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../cad_resources/index.html">Computer Aided Design (CAD)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Electrostatic Discharge</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../hardware_and_software_configuration/configuring/managing_esd/managing-esd.html">Managing ESD Effects</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Manufacturing</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../manufacturing/index.html">Manufacturing Methods</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Team Resources</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/faqs.html">Common Team FAQs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../sponsors/software/software.html">Team Complimentary Software</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../sponsors/discounts/discounts.html">Team Discounts</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FTC Docs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../booklets/index.html">Booklets</a></li>
<li class="toctree-l1"><a class="reference external" href="https://ftc-docs.firstinspires.org/projects/ftcdocs-archive/en/latest/index.html">Archive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ftc_docs/form/form.html">Site Feedback Form</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../contrib/index.html">Contributing to FTC Docs</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">FIRST Tech Challenge Docs</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Programming Resources</a></li>
      <li class="breadcrumb-item active">TensorFlow for CENTERSTAGE presented by RTX</li>
<li class="wy-breadcrumbs-aside" style="padding-inline-start: 6px;">
</li>

      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/programming_resources/vision/tensorflow_cs_2023/tensorflow-cs-2023.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="tensorflow-for-centerstage-presented-by-rtx">
<h1>TensorFlow for CENTERSTAGE presented by RTX<a class="headerlink" href="#tensorflow-for-centerstage-presented-by-rtx" title="Permalink to this heading"></a></h1>
<section id="what-is-tensorflow">
<h2>What is TensorFlow?<a class="headerlink" href="#what-is-tensorflow" title="Permalink to this heading"></a></h2>
<p><em>FIRST</em> Tech Challenge teams can use <a class="reference external" href="https://ai.google.dev/edge/litert">TensorFlow Lite</a>, a lightweight version of Google’s
<a class="reference external" href="https://www.tensorflow.org/">TensorFlow</a> machine learning technology that
is designed to run on mobile devices such as an Android smartphone or the <a class="reference external" href="https://www.revrobotics.com/rev-31-1595/">REV
Control Hub</a>.  A <em>trained
TensorFlow model</em> was developed to recognize the white <code class="docutils literal notranslate"><span class="pre">Pixel</span></code> game piece used in
the <strong>2023-2024 CENTERSTAGE presented by RTX</strong> challenge.</p>
<figure class="align-center" id="id1">
<a class="reference internal image-reference" href="../../../_images/pixel.png"><img alt="CENTERSTAGE Pixel" src="../../../_images/pixel.png" style="height: 400px;" /></a>
<figcaption>
<p><span class="caption-text">This season’s TFOD model can recognize a white Pixel</span><a class="headerlink" href="#id1" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>TensorFlow Object Detection (TFOD) has been integrated into the control system
software to identify a white <code class="docutils literal notranslate"><span class="pre">Pixel</span></code> during a match. The SDK (SDK
version 9.0) contains TFOD Sample OpModes and Detection Models that can
recognize the white <code class="docutils literal notranslate"><span class="pre">Pixel</span></code> at various poses (but not all).</p>
</section>
<section id="how-might-a-team-use-tensorflow-this-season">
<h2>How Might a Team Use TensorFlow this season?<a class="headerlink" href="#how-might-a-team-use-tensorflow-this-season" title="Permalink to this heading"></a></h2>
<p>For this season’s challenge the field is randomized during the Pre-Match stage.
This randomization causes the white <code class="docutils literal notranslate"><span class="pre">Pixel</span></code> placed on Spike Marks to be placed on
either the Left, Center, or Right Spike Mark. During Autonomous, Robots must
independently determine which of the three Spike Marks (Left, Center, Right)
the white <code class="docutils literal notranslate"><span class="pre">Pixel</span></code> was placed on. To do this, robots using a Webcam or a camera on
a Robot Controller Smartphone can inspect Spike Mark locations to determine if
a white <code class="docutils literal notranslate"><span class="pre">Pixel</span></code> is present. Once the robot has correctly identified which Spike
Mark the white <code class="docutils literal notranslate"><span class="pre">Pixel</span></code> is present on, the robot can then perform additional
actions based on that position that will yield additional points.</p>
<p>Teams also have the opportunity to replace the white <code class="docutils literal notranslate"><span class="pre">Pixel</span></code> with an object
of their own creation, within a few guidelines specified in the Game
Competition. This object, or Team Game Element, can be optimized to help the
team identify it more easily and custom TensorFlow inference models can be
created to facilitate recognition. As the field is randomized, the team’s Team
Game Element will be placed on the Spike Marks as the white <code class="docutils literal notranslate"><span class="pre">Pixel</span></code> would
have, and the team must identify and use the Team Game Element the same as if
it were a white <code class="docutils literal notranslate"><span class="pre">Pixel</span></code> on a Spike Mark.</p>
</section>
<section id="sample-opmodes">
<h2>Sample OpModes<a class="headerlink" href="#sample-opmodes" title="Permalink to this heading"></a></h2>
<p>Teams have the option of using a custom inference model with the <em>FIRST</em> Tech
Challenge software or to use the game-specific default model provided. As noted
above, the <em>FIRST</em> Machine Learning Toolchain is a streamlined tool for training
your own TFOD models.</p>
<p>The FIRST Tech Challenge software (Robot Controller App and Android Studio
Project) includes sample OpModes (Blocks and Java versions) that demonstrate
how to use <strong>the default inference model</strong>.  These tutorials show how to use
the sample OpModes, using examples from previous <em>FIRST</em> Tech Challenge
seasons, but demonstrate the process for use in any season.</p>
<ul class="simple">
<li><p><a class="reference internal" href="../blocks_tfod_opmode/blocks-tfod-opmode.html"><span class="doc">Blocks Sample OpMode for TensorFlow Object Detection</span></a></p></li>
<li><p><a class="reference internal" href="../java_tfod_opmode/java-tfod-opmode.html"><span class="doc">Java Sample OpMode for TFOD</span></a></p></li>
</ul>
<p>Using the sample OpModes, teams can practice identifying white <code class="docutils literal notranslate"><span class="pre">Pixels</span></code> placed
on Spike Marks. The sample OpMode <code class="docutils literal notranslate"><span class="pre">ConceptTensorFlowObjectDetectionEasy</span></code> is
a simple OpMode to use to detect a <code class="docutils literal notranslate"><span class="pre">Pixel</span></code> - it is a very basic OpMode simplified
for beginner teams to perform basic <code class="docutils literal notranslate"><span class="pre">Pixel</span></code> detection.</p>
<figure class="align-center" id="id2">
<a class="reference internal image-reference" href="../../../_images/easypixeldetect.png"><img alt="Pixel Detection" src="../../../_images/easypixeldetect.png" style="width: 75%;" /></a>
<figcaption>
<p><span class="caption-text">Example Detection of a Pixel</span><a class="headerlink" href="#id2" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>It is important to note that if the detection of the object is below the
minimum confidence threshold, the detection will not be shown - it is important
to set the minimum detection threshold appropriately.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The default minimum confidence threshold provided in the Sample OpMode (75%)
is only provided as an example; depending on local conditions (lighting,
image wear, etc…) it may be necessary to lower the minimum confidence in
order to increase TensorFlow’s likelihood to see all possible image
detections. However, due to its simplified nature it is not possible to
change the minimum confidence using the <code class="docutils literal notranslate"><span class="pre">Easy</span></code> OpMode. Instead, you will
have to use the normal OpMode.</p>
</div>
</section>
<section id="notes-on-training-the-centerstage-model">
<h2>Notes on Training the CENTERSTAGE Model<a class="headerlink" href="#notes-on-training-the-centerstage-model" title="Permalink to this heading"></a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">Pixel</span></code> game piece posed an interesting challenge for TensorFlow Object
Detection (TFOD). As is warned in the Machine Learning Toolkit documentation,
TFOD is not very good with recognizing and differentiating simple geometric
shapes, nor distinguishing between specific colors; instead, TFOD is good at
detecting <em>patterns</em>. TFOD needs to be able to recognize a unique <em>pattern</em>,
and while there is a small amount of patterning in the ribbing of the
<code class="docutils literal notranslate"><span class="pre">Pixel</span></code>, in various lighting conditions it’s dubious how much the ribbing
will be able to be seen.  Even in the image at the top of this document, the
ribbing can only be seen due to the specific shadows that the game piece has
been provided. Even in optimal testing environments, it was difficult to
capture video of the object that nicely highlighted the ribbing enough for
TensorFlow to use for pattern recognition. This highlighted the inability to
guarantee optimal <code class="docutils literal notranslate"><span class="pre">Pixel</span></code> characteristics in unknown lighting environments
for TFOD.</p>
<p>Another challenge with training the model had to do with how the <code class="docutils literal notranslate"><span class="pre">Pixel</span></code>
looks at different pose angles. When the camera is merely a scant few inches
from the floor, the <code class="docutils literal notranslate"><span class="pre">Pixel</span></code> can almost look like a solid object; at times
there may be sufficient shadows to see that there is a hole in the center of
the object, but not always. However, if the camera was several inches off the
floor the <code class="docutils literal notranslate"><span class="pre">Pixel</span></code> looked differently, as the mat or colored tape could be
seen through the hole in the middle of the object. This confused the neural
network and made it extremely difficult to train, and the resulting models
eventually recognized any “sufficiently light colored blob” as a <code class="docutils literal notranslate"><span class="pre">Pixel</span></code>.
This was not exactly ideal.</p>
<p>Even with the best of images, the Machine Learning algorithms had a difficult
time determining what <em>was</em> a <code class="docutils literal notranslate"><span class="pre">Pixel</span></code> and what wasn’t. What ended up working
was providing NOT ONLY images of the <code class="docutils literal notranslate"><span class="pre">Pixel</span></code> in different poses, but also
several white objects that WERE NOT a <code class="docutils literal notranslate"><span class="pre">Pixel</span></code>. This was fundamental to
helping TensorFlow train itself to understand that “All <code class="docutils literal notranslate"><span class="pre">Pixels</span></code> are White
Objects, but not all White Objects are <code class="docutils literal notranslate"><span class="pre">Pixels</span></code>.”</p>
<p>To provide some additional context on this, here are a few examples of labeled
frames that illustrate the challenges and techniques in dealing with the
<code class="docutils literal notranslate"><span class="pre">Pixel</span></code> game piece.</p>
<div class="sd-container-fluid sd-sphinx-override sd-mb-4 docutils">
<div class="sd-row sd-row-cols-1 sd-row-cols-xs-1 sd-row-cols-sm-2 sd-row-cols-md-2 sd-row-cols-lg-2 sd-g-2 sd-g-xs-2 sd-g-sm-2 sd-g-md-2 sd-g-lg-2 docutils">
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-header sd-bg-dark font-weight-bold sd-text-white docutils">
<p class="sd-card-text">Training Frame 1</p>
</div>
<div class="sd-card-body sd-text-left body docutils">
<figure class="align-center">
<a class="reference internal image-reference" href="../../../_images/trainingblownout.png"><img alt="Pixel that's saturated" src="../../../_images/trainingblownout.png" style="width: 100%;" /></a>
</figure>
</div>
<div class="sd-card-footer docutils">
<p class="sd-card-text">Pixel Saturation (No Ribs)</p>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-header sd-bg-dark font-weight-bold sd-text-white docutils">
<p class="sd-card-text">(Rejected) Training Frame 2</p>
</div>
<div class="sd-card-body sd-text-left body docutils">
<figure class="align-center">
<a class="reference internal image-reference" href="../../../_images/lowanglepixel.png"><img alt="Pixel at low angle" src="../../../_images/lowanglepixel.png" style="width: 100%;" /></a>
</figure>
</div>
<div class="sd-card-footer docutils">
<p class="sd-card-text">Camera Too Low (White Blob)</p>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-header sd-bg-dark font-weight-bold sd-text-white docutils">
<p class="sd-card-text">Training Frame 3</p>
</div>
<div class="sd-card-body sd-text-left body docutils">
<figure class="align-center">
<a class="reference internal image-reference" href="../../../_images/ribsexposed.png"><img alt="Rare good image" src="../../../_images/ribsexposed.png" style="width: 100%;" /></a>
</figure>
</div>
<div class="sd-card-footer docutils">
<p class="sd-card-text">Actual Good Image with Ribbing (Rare)</p>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-header sd-bg-dark font-weight-bold sd-text-white docutils">
<p class="sd-card-text">Training Frame 4</p>
</div>
<div class="sd-card-body sd-text-left body docutils">
<figure class="align-center">
<a class="reference internal image-reference" href="../../../_images/negatives.png"><img alt="Pixel with non-pixel objects" src="../../../_images/negatives.png" style="width: 100%;" /></a>
</figure>
</div>
<div class="sd-card-footer docutils">
<p class="sd-card-text">Pixel with non-Pixel Objects</p>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="using-the-default-centerstage-model">
<h2>Using the Default CENTERSTAGE Model<a class="headerlink" href="#using-the-default-centerstage-model" title="Permalink to this heading"></a></h2>
<p>In the previous section it’s described how the height of the camera from the floor
has a huge effect on how the <code class="docutils literal notranslate"><span class="pre">Pixel</span></code> is seen; too low and the object can look
like a single “blob” of color, and too high and the object will look similar to
a white donut. When training the model, it was decided that the Donut approach was
the best - train the model to recognize the <code class="docutils literal notranslate"><span class="pre">Pixel</span></code> from above to provide a
clear and consistent view of the <code class="docutils literal notranslate"><span class="pre">Pixel</span></code>. Toss in some angled shots as well, along
with some additional extra objects just to give TensorFlow some perspective, and
a model is born. <strong>But wait, how does that affect detection of the Pixel from the
robot’s starting configuration?</strong></p>
<p>In CENTERSTAGE, using the default CENTERSTAGE model, it is unlikely that a
robot will be able to get a consistent detection of a White <code class="docutils literal notranslate"><span class="pre">Pixel</span></code> from the
starting location. In order to get a good detection, the robot’s camera needs
to be placed fairly high up, and angled down to be able to see the gray tile,
blue tape, or red tape peeking out of the center of the <code class="docutils literal notranslate"><span class="pre">Pixel</span></code>. Thanks to
the center structure on the field this season, it’s doubtful that a team will
want to have an exceptionally tall robot - likely no more than 14 inches tall,
but most will want to be under 12 inches to be safe (depending on your strategy
- please don’t let this article define your game strategy!). The angle that
your robot’s camera will have with the Pixel in the starting configuration
makes this seem unlikely.</p>
<p>Here are several images of detected and non-detected <code class="docutils literal notranslate"><span class="pre">Pixels</span></code>. Notice that
the center of the object must be able to see through to what’s under the
<code class="docutils literal notranslate"><span class="pre">Pixel</span></code> in order for the object to be detected as a <code class="docutils literal notranslate"><span class="pre">Pixel</span></code>.</p>
<div class="sd-container-fluid sd-sphinx-override sd-mb-4 docutils">
<div class="sd-row sd-row-cols-1 sd-row-cols-xs-1 sd-row-cols-sm-2 sd-row-cols-md-2 sd-row-cols-lg-2 sd-g-2 sd-g-xs-2 sd-g-sm-2 sd-g-md-2 sd-g-lg-2 docutils">
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-header sd-bg-dark font-weight-bold sd-text-white docutils">
<p class="sd-card-text">Non-Detected Pixel #1</p>
</div>
<div class="sd-card-body sd-text-left body docutils">
<figure class="align-center">
<a class="reference internal image-reference" href="../../../_images/pixelnodetect1.png"><img alt="Pixel Not Detected 1" src="../../../_images/pixelnodetect1.png" style="width: 100%;" /></a>
</figure>
</div>
<div class="sd-card-footer docutils">
<p class="sd-card-text">Pixel Not Detected, Angle Too Low</p>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-header sd-bg-dark font-weight-bold sd-text-white docutils">
<p class="sd-card-text">Non-Detected Pixel #2</p>
</div>
<div class="sd-card-body sd-text-left body docutils">
<figure class="align-center">
<a class="reference internal image-reference" href="../../../_images/pixelnodetect2.png"><img alt="Pixel Not Detected 2" src="../../../_images/pixelnodetect2.png" style="width: 100%;" /></a>
</figure>
</div>
<div class="sd-card-footer docutils">
<p class="sd-card-text">Pixel Not Detected, Angle Too Low</p>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-header sd-bg-dark font-weight-bold sd-text-white docutils">
<p class="sd-card-text">Detected Pixel #1</p>
</div>
<div class="sd-card-body sd-text-left body docutils">
<figure class="align-center">
<a class="reference internal image-reference" href="../../../_images/pixeldetect1.png"><img alt="Pixel Detected 1" src="../../../_images/pixeldetect1.png" style="width: 100%;" /></a>
</figure>
</div>
<div class="sd-card-footer docutils">
<p class="sd-card-text">Pixel Detected, Min Angle</p>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-header sd-bg-dark font-weight-bold sd-text-white docutils">
<p class="sd-card-text">Detected Pixel #2</p>
</div>
<div class="sd-card-body sd-text-left body docutils">
<figure class="align-center">
<a class="reference internal image-reference" href="../../../_images/pixeldetect2.png"><img alt="Pixel Detected 2" src="../../../_images/pixeldetect2.png" style="width: 100%;" /></a>
</figure>
</div>
<div class="sd-card-footer docutils">
<p class="sd-card-text">Pixel Detected, Better Angle</p>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-header sd-bg-dark font-weight-bold sd-text-white docutils">
<p class="sd-card-text">Detected Pixel #3</p>
</div>
<div class="sd-card-body sd-text-left body docutils">
<figure class="align-center">
<a class="reference internal image-reference" href="../../../_images/pixeldetect3.png"><img alt="Pixel Detected 3" src="../../../_images/pixeldetect3.png" style="width: 100%;" /></a>
</figure>
</div>
<div class="sd-card-footer docutils">
<p class="sd-card-text">Pixel Detected, Min Angle on Tape</p>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-header sd-bg-dark font-weight-bold sd-text-white docutils">
<p class="sd-card-text">Detected Pixel #4</p>
</div>
<div class="sd-card-body sd-text-left body docutils">
<figure class="align-center">
<a class="reference internal image-reference" href="../../../_images/pixeldetect4.png"><img alt="Pixel Detected 4" src="../../../_images/pixeldetect4.png" style="width: 100%;" /></a>
</figure>
</div>
<div class="sd-card-footer docutils">
<p class="sd-card-text">Pixel Detected, Top-Down View</p>
</div>
</div>
</div>
</div>
</div>
<p>Therefore, there are two options for detecting the <code class="docutils literal notranslate"><span class="pre">Pixel</span></code>:</p>
<ol class="arabic simple">
<li><p>The camera can be on a retractable/moving system, so that the camera is elevated to
a desirable height during the start of Autonomous, and then retracts before moving
around.</p></li>
<li><p>The robot will have to drive closer to the Spike Marks in order to be able to
properly detect the <code class="docutils literal notranslate"><span class="pre">Pixels</span></code>.</p></li>
</ol>
<p>For the second option (driving closer), the camera’s field of view might pose a
challenge if it’s desirable for all three Spike Marks to be always in view. If
using a Logitech C270 camera, perhaps using a Logitech C920 with a wider field
of view might help to some degree. This completely depends on the height of the
camera and how far the robot must be driven in order to properly recognize a
<code class="docutils literal notranslate"><span class="pre">Pixel</span></code>. Teams can also simply choose to point their webcam to the CENTER and
LEFT Spike Marks, for example, and drive closer to those targets, and if a
<code class="docutils literal notranslate"><span class="pre">Pixel</span></code> is not detected then by process of elimination it must be on the
RIGHT Spike Mark.</p>
</section>
<section id="selecting-objects-for-the-team-prop">
<h2>Selecting objects for the Team Prop<a class="headerlink" href="#selecting-objects-for-the-team-prop" title="Permalink to this heading"></a></h2>
<p>Selecting objects to use for your custom Team Prop can seem daunting. Questions
swirl like “What shapes are going to be recognized best?”, “If I cannot have
multiple colors, how do I make patterns?”, and “How do I make this easier on myself?”.
Hopefully this section will help you understand a little more about TensorFlow
and how to get the most out of it.</p>
<p>First, it’s important to note that TensorFlow has the following quirks/behaviors:</p>
<ul class="simple">
<li><p>In order to run TensorFlow on mobile phones, <em>FIRST</em> Tech Challenge uses a very small core
model resolution. This means the image is downscaled from the high definition
webcam image to one that is only 300x300 pixels. This means that medium and
small objects within the webcam images may be reduced to very small
indistinguishable clusters of pixels in the target image. Keep the objects in
the view of the camera large, and train for a wide range of image sizes.</p></li>
<li><p>TensorFlow is not really good at differentiating simple geometric shapes. TensorFlow
Object Detection is an object classifier, and similar geometric shapes will
classify similarly. Humans are much better at differentiating geometric shapes than
neural net algorithms, like TensorFlow, at the present.</p></li>
<li><p>TensorFlow is great at pattern detection, but that means that within the footprint
of the object you need one or more repeating or unique patterns. The larger the
pattern the easier it will be for TensorFlow to detect the pattern at a
distance.</p></li>
</ul>
<p>So what kinds of patterns are good for TensorFlow? Let’s explore a few examples:</p>
<ol class="arabic simple">
<li><p>Consider the shape of a <a class="reference external" href="https://chess.fandom.com/wiki/Rook">chess board Rook</a>.
The Rook itself is mostly uniform all around, no matter how you rotate the
object it more or less looks the same. Not much patterning there. However,
the top of the Rook is very unique and patterned.  Exaggerating the
“battlements”, the square-shaped parts of the top of the Rook, can provide
unique patterning that TensorFlow can distinguish.</p></li>
<li><p>Consider the outline of a <a class="reference external" href="https://fineartamerica.com/featured/knight-chess-pieces-ktsdesign.html?product=poster">chess Knight</a>,
as the “head” of the Knight is facing to the right or to the left. That
profile is very distinguishable as the head of a horse. That specific animal
is one that <a class="reference external" href="https://ftc-community.firstinspires.org/t/tensorflow-model-zoo-models/159">model zoos</a>
have been optimized for, so it’s definitely a shape that TensorFlow can be
trained to recognize.</p></li>
<li><p>Consider the patterning in a fancy <a class="reference external" href="https://www.google.com/search?q=wrought+iron+fence+patterns">wrought-iron fence</a>. If made
thick enough, those repeating patterns can be recognized by a TensorFlow
model. Like the Chess Board Rook, it might be wise to make the object round
so that the pattern is similar and repeats now matter how the object is
rotated. If allowed, having multiple shades of color can also help make a
more-unique patterning on the object (e.g. multiple shades of red, likely
must consult the <a class="reference external" href="https://ftc-qa.firstinspires.org">Q&amp;A</a>).</p></li>
<li><p>TensorFlow can be used to
<a class="reference external" href="https://github.com/KundanBalse/Plant-Detection-Using-TensorFlow#3a-collect-images">Detect Plants</a>
and all of the plants are a single color. Similar techniques can be reverse-engineered
(make objects of different “patterns” similar to plants) to create an object that
can be detected and differentiated from other objects on the game field.</p></li>
</ol>
<p>Hopefully this gives you quite a few ideas for how to approach this challenge!</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../../../apriltag/apriltag_tips/decode_apriltag/decode-apriltag.html" class="btn btn-neutral float-left" title="AprilTag Challenges in DECODE presented by RTX" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../tensorflow_pp_2022/tensorflow_pp_2022.html" class="btn btn-neutral float-right" title="TensorFlow for POWERPLAY presented by Raytheon Technologies" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo" style="display: flex">
  
    <div id="container" style="width: 50%; white-space:nowrap;">

      <div>
        &#169; 2025 <i>FIRST</i>
      </div>

      <div>
        <p><a href="../../../tos/tos.html">Terms of Service</a></p>
      </div>
      <div>
        <p><a class="external" href="https://www.firstinspires.org/privacy-policy">Privacy Policy</a></p>
      </div>
      <div>
        <p><a class="external" href="https://www.firstinspires.org/programs/youth-protection-program">Report an Incident</a></p>
      </div>

      <div>
      </div>
    </div>

    <div align="right" style='flex-grow:1; text-align: right'>
      Season Presenting Sponsor
      <figure>
        <img src="../../../_static/RTX.png" alt="RTX" class="invert-img" width="200" align="right"/>
      </figure>
    </div>
  </div>
<!--
  <div> 
  </div>
  -->
</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

</body>
</html>